# BeatifulSoup类的使用

## 安装

直接pip install BeatifulSoup4, 然后以如下形式导入即可

```python
from bs4 import BeautifulSoup
url = "https://python123.io/ws/demo.html"
re = requests.get(url)
demo = re.text
# 为该库指定解析器，是第二个参数
soup = BeautifulSoup(demo, "html.parser")
```

## BeatifulSoup库的基本元素

![BeatifulSoup库的基本元素](http://oos.sfzzz.xyz/2020_07_05_16_57_25_1.png)

* 获取**标签**，任何存在的标签都可以用```soup.tag```的形式获取，如果有多个相同的标签 时，该方法只能返回第一个如：

  ```python
  atag = soup.a
  print(atag)
  ```

  第一行代码获取soup解析出来的类中的a标签，然后打印，这里只会打印第一个

* 获取标签的**名字**使用```soup.a.name```, 即是获取a标签的名字

* 获取标签的**属性**，使用```soup.a.attrs```来获取，注意获取到的是一个**字典（dict）**，也就是键值对的形式，可以通过如下方式访问

  ```python
  atag.attrs.get("href")
  atag.attrs['href']
  ```

* 获取一对标签中间的字符串，使用`soup.a.string`来获取，是一个bs4.element.NavigableString类

## 基于bs4库的HTML内容遍历方法

### 标签树的下行遍历

![image-20200705201525348](http://oos.sfzzz.xyz/2020_07_05_20_15_25_1.png)

### 标签树的上行遍历

![上行遍历](http://oos.sfzzz.xyz/2020_07_05_20_25_29_1.png)

### 树的平行遍历

![平行遍历](http://oos.sfzzz.xyz/2020_07_05_23_06_42_1.png)

## 信息标记的三种形式

* XML: eXtensible Markup Language，基于HTML格式发展来的，通过标签形式来标记信息
* JSON: JavaScript Object Notation，以键值对的形式标记信息，可以嵌套
* YAML: YAML Ain't Markup Language, 空格缩进表达所属的关系，用 ‘ - ’ 表达对应关系，| 标记一个很长的段，# 注释

## 信息提取的一般方法

* 完整解析信息的标记形式，再提取关键信息，需要标记解析器，例如bs4的标签树遍历
* 无视标记信息，直接搜索关键信息。优点：提取过程简洁，速度较快。
* 一般都是融合方法。

实例：提取HTML中的所有a标签

```python
for link in soup.find_all('a'):
    print(link.attrs['href'])
```

上例中，通过一个迭代器迭代查找 `soup` 中所有的 `a` 标签，然后打印 `a` 标签的 `href` 属性值

## 基于bs4库的HTML内容查找方法

![find_all方法介绍](http://oos.sfzzz.xyz/2020_07_06_14_06_18_1.png)

```python
for link in soup.find_all(re.compile('b')):
    print(link.name)
```

import re库之后，re.compile('b')作为soup.find_all() 的参数，即是匹配含有 ' b ' 的标签

```python
# 搜索p标签中，属性值含有course的标签
print(soup.find_all('p', 'course'))
# 搜索id="link1"的标签
print(soup.find_all(id="link1"))
# 正则搜索id含有link的标签,需要引入正则表达式（re）库
print(soup.find_all(id=re.compile("link")))
# 由于find_all函数很常用，因此可以简写为如下
soup()
html()
```

![扩展方法](http://oos.sfzzz.xyz/2020_07_06_14_07_04_1.png)

![格式化输出的问题](http://oos.sfzzz.xyz/2020_07_06_15_35_59_1.png)

## 实例：爬取2020中国大学排名

```python
import requests
from bs4 import BeautifulSoup
import bs4


def getHTML(url):
    try:
        req = requests.get(url, timeout=30)
        # 产生异常信息？
        req.raise_for_status()
        req.encoding = "UTF-8"
        return req.text
    except:
        print("爬取失败")
        return ""


# 提取信息到一个list
def getUList(htmlText):
    soup = BeautifulSoup(htmlText, "html.parser")
    ulist = []
    for tr in soup.find("tbody").children:
        if isinstance(tr, bs4.element.Tag):
            tds = tr("td")
            ulist.append([tds[0].string, tds[1].string, tds[2].string, tds[3].string, tds[4].string])
    return ulist


def main():
    url = "http://www.zuihaodaxue.com/zuihaodaxuepaiming2020.html"
    htmlText = getHTML(url)
    ulist = getUList(htmlText)
    str = "{:^10}\t{:^10}\t{:^10}\t{:^10}\t{:^10}"
    print(str.format("排名", "学校", "地址", "类型", "综合得分"))
    for item in ulist:
        print(str.format(item[0], item[1], item[2], item[3], item[4]))


main()

```

